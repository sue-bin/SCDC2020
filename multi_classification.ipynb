{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzRAk2F2hiYerNTh58MEjQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqaktcnxjr-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1221c0e3-ed41-4d47-9870-d4621ce4d0cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJYd9JDekbTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "17cac9b6-4bc0-4353-f850-a0d9c5dfd940"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from patsy import dmatrices\n",
        "import statsmodels.api as sm;\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "%matplotlib inline\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n60p_LyVlyRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3NKtTc8sNZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "info_df_raw = pd.read_csv(\"/content/drive/My Drive/데이터분석/samsung/info1.csv\")\n",
        "feat_df_raw = pd.read_csv(\"/content/drive/My Drive/데이터분석/samsung/samp_cst_feat.csv\")\n",
        "train_df_raw = pd.read_csv(\"/content/drive/My Drive/데이터분석/samsung/samp_train.csv\")\n",
        "dtype_df_raw = pd.read_excel(\"/content/drive/My Drive/데이터분석/samsung/variable_dtype.xlsx\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM0hvGlii1-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "info_df = info_df_raw.copy()\n",
        "feat_df = feat_df_raw.copy()\n",
        "train_df = train_df_raw.copy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIu-leKEkuIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype_dict = dtype_df_raw.set_index('Variable_Name')['dType'].to_dict()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZbA8fmwk0EM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "c4fb3c6f-c20f-4f8d-ed96-4aedc0555aa4"
      },
      "source": [
        "#카테고리컬 변수타입 변환\n",
        "for w in feat_df_raw.columns:\n",
        "  if w in dtype_dict.keys():\n",
        "    if dtype_dict[w] == \"categorical\":\n",
        "      feat_df[w] = feat_df_raw[w].astype(str)\n",
        "feat_df.dtypes.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cst_id_di      int64\n",
              "VAR002       float64\n",
              "VAR003       float64\n",
              "VAR004       float64\n",
              "VAR005       float64\n",
              "VAR006       float64\n",
              "VAR007        object\n",
              "VAR008       float64\n",
              "VAR009       float64\n",
              "VAR010       float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A_RU2tZk_1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#카테고리컬 변수들 행 이름\n",
        "obj_col = []\n",
        "numerical_col = [] \n",
        "for w in dtype_dict:\n",
        "  if dtype_dict[w] == \"categorical\":\n",
        "    obj_col.append(w)\n",
        "  else:\n",
        "    numerical_col.append(w)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr_4Nd2JlBvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d9f1673-baad-4ac1-fc9e-2d1168568afc"
      },
      "source": [
        "##categorical은 다 dummy variables\n",
        "for i in obj_col:\n",
        "  print(feat_df[i].value_counts())\n",
        "  print()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    8633\n",
            "1    1491\n",
            "Name: VAR007, dtype: int64\n",
            "\n",
            "0    5430\n",
            "1    4694\n",
            "Name: VAR015, dtype: int64\n",
            "\n",
            "0    8009\n",
            "1    2115\n",
            "Name: VAR018, dtype: int64\n",
            "\n",
            "0    9926\n",
            "1     198\n",
            "Name: VAR026, dtype: int64\n",
            "\n",
            "0    7606\n",
            "1    2518\n",
            "Name: VAR059, dtype: int64\n",
            "\n",
            "0    7324\n",
            "1    2800\n",
            "Name: VAR066, dtype: int64\n",
            "\n",
            "1    8723\n",
            "0    1401\n",
            "Name: VAR067, dtype: int64\n",
            "\n",
            "0    8166\n",
            "1    1958\n",
            "Name: VAR070, dtype: int64\n",
            "\n",
            "0    9314\n",
            "1     810\n",
            "Name: VAR071, dtype: int64\n",
            "\n",
            "0    8769\n",
            "1    1355\n",
            "Name: VAR077, dtype: int64\n",
            "\n",
            "0    9738\n",
            "1     386\n",
            "Name: VAR078, dtype: int64\n",
            "\n",
            "0    9515\n",
            "1     609\n",
            "Name: VAR094, dtype: int64\n",
            "\n",
            "0    9158\n",
            "1     966\n",
            "Name: VAR096, dtype: int64\n",
            "\n",
            "0    8956\n",
            "1    1168\n",
            "Name: VAR097, dtype: int64\n",
            "\n",
            "0    9306\n",
            "1     818\n",
            "Name: VAR098, dtype: int64\n",
            "\n",
            "0    8434\n",
            "1    1690\n",
            "Name: VAR107, dtype: int64\n",
            "\n",
            "0    7949\n",
            "1    2175\n",
            "Name: VAR111, dtype: int64\n",
            "\n",
            "0    7452\n",
            "1    2672\n",
            "Name: VAR124, dtype: int64\n",
            "\n",
            "0    7249\n",
            "1    2875\n",
            "Name: VAR127, dtype: int64\n",
            "\n",
            "0    9952\n",
            "1     172\n",
            "Name: VAR143, dtype: int64\n",
            "\n",
            "0    9485\n",
            "1     639\n",
            "Name: VAR144, dtype: int64\n",
            "\n",
            "0    8960\n",
            "1    1164\n",
            "Name: VAR145, dtype: int64\n",
            "\n",
            "0    8760\n",
            "1    1364\n",
            "Name: VAR148, dtype: int64\n",
            "\n",
            "1    5410\n",
            "0    4714\n",
            "Name: VAR165, dtype: int64\n",
            "\n",
            "0    8620\n",
            "1    1504\n",
            "Name: VAR177, dtype: int64\n",
            "\n",
            "0    8299\n",
            "1    1825\n",
            "Name: VAR179, dtype: int64\n",
            "\n",
            "0    8405\n",
            "1    1719\n",
            "Name: VAR199, dtype: int64\n",
            "\n",
            "0    8764\n",
            "1    1360\n",
            "Name: VAR208, dtype: int64\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEfbo3H4lDOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_df = feat_df_raw.copy()\n",
        "total_df['label'] = train_df_raw['MRC_ID_DI']"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZS8RXmxlHh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = total_df.copy()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlZJXDTIltZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(['label'], axis = 1)\n",
        "Y = df['label']\n",
        "X = StandardScaler().fit_transform(X)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdS7PV5FlvOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8d98264f-0dd3-4c84-91b4-0d2dcd600b67"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=5)\n",
        "X_pca = pca.fit_transform(X)\n",
        "PCA_df = pd.DataFrame(data = X_pca, columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
        "PCA_df = pd.concat([PCA_df, df['label']], axis = 1)\n",
        "PCA_df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC1</th>\n",
              "      <th>PC2</th>\n",
              "      <th>PC3</th>\n",
              "      <th>PC4</th>\n",
              "      <th>PC5</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.279507</td>\n",
              "      <td>-3.813251</td>\n",
              "      <td>5.084972</td>\n",
              "      <td>-5.013252</td>\n",
              "      <td>-0.228353</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.681195</td>\n",
              "      <td>4.586905</td>\n",
              "      <td>-2.685685</td>\n",
              "      <td>2.918950</td>\n",
              "      <td>-3.614974</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-14.916882</td>\n",
              "      <td>-1.823236</td>\n",
              "      <td>0.040112</td>\n",
              "      <td>-1.621080</td>\n",
              "      <td>-5.169928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-3.165472</td>\n",
              "      <td>4.684853</td>\n",
              "      <td>-3.915588</td>\n",
              "      <td>-4.432158</td>\n",
              "      <td>1.878737</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.599368</td>\n",
              "      <td>7.075075</td>\n",
              "      <td>4.594998</td>\n",
              "      <td>2.728054</td>\n",
              "      <td>-0.535296</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         PC1       PC2       PC3       PC4       PC5  label\n",
              "0   7.279507 -3.813251  5.084972 -5.013252 -0.228353      0\n",
              "1  14.681195  4.586905 -2.685685  2.918950 -3.614974      8\n",
              "2 -14.916882 -1.823236  0.040112 -1.621080 -5.169928      0\n",
              "3  -3.165472  4.684853 -3.915588 -4.432158  1.878737      5\n",
              "4  19.599368  7.075075  4.594998  2.728054 -0.535296      6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjnKY9fpmyc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d39a79f7-7107-415a-ae55-84845f71fdd5"
      },
      "source": [
        "print(pca.explained_variance_)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[85.45969829 23.29474153 20.62239031 12.33915741  7.18065995]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9McHTVHoSi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d107fcf8-edc4-45b8-85f1-76cc169a8818"
      },
      "source": [
        "Y.values"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 8, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Mfwsf6nD5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaCt2WNAxt-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(total_df.drop(\"label\",axis=1), total_df[\"label\"], test_size = 0.30, random_state = 2020)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGQyZLwnUx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 15\n",
        "learning_rate = 0.0001\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=5, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(11, activation='softmax'))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooLCm-CFq67M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0y-9E_orAt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "b3f20ee5-d9a7-432f-e483-2c0deab5044e"
      },
      "source": [
        "hist = model.fit(x_train, y_train, epochs=1000, batch_size=batch)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-f162db6d8f06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 11) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm5l2STWrDPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsMpHVzrs0Ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "709c4fbf-63f2-4694-935f-ff1e530c8069"
      },
      "source": [
        "!pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1\n",
            "  Cloning https://github.com/keras-team/keras-tuner.git (to revision 1.0.2rc1) to /tmp/pip-req-build-0rtd2mou\n",
            "  Running command git clone -q https://github.com/keras-team/keras-tuner.git /tmp/pip-req-build-0rtd2mou\n",
            "  Running command git checkout -q 0fb69434a132093518e0e53d40020145ae192629\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (20.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (1.18.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner==1.0.2rc1) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner==1.0.2rc1) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2rc1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2rc1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2rc1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2rc1) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner==1.0.2rc1) (0.16.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2rc1-cp36-none-any.whl size=85424 sha256=76591834eeedfe7a79679b094f139038937ac42aa8ed374e2acd82dd10ba42cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7nq68zt3/wheels/af/c9/7c/6ea01f9753a5dd1484136b4cb7b33a0a7fba253e5c74ade5af\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=833595f689a3975009cba005b73bc86d70d490f025ad32fa70f364c4e509c41c\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.3 keras-tuner-1.0.2rc1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYB9DTl_s0tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import autokeras as ak"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-iUkrrAs5D_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ede03eb3-146f-4a72-a6d7-28f6e85849d1"
      },
      "source": [
        "clf = ak.StructuredDataClassifier(\n",
        "    overwrite=True,\n",
        "    max_trials=3)\n",
        "# Feed the structured data classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=150)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 02m 09s]\n",
            "val_accuracy: 0.8021582961082458\n",
            "\n",
            "Best val_accuracy So Far: 0.8021582961082458\n",
            "Total elapsed time: 00h 06m 09s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/150\n",
            "222/222 [==============================] - 1s 5ms/step - loss: 209833488.0000 - accuracy: 0.6689\n",
            "Epoch 2/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 70796544.0000 - accuracy: 0.6741\n",
            "Epoch 3/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 68285184.0000 - accuracy: 0.6706\n",
            "Epoch 4/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 65767884.0000 - accuracy: 0.6715\n",
            "Epoch 5/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 73603680.0000 - accuracy: 0.6689\n",
            "Epoch 6/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 61936220.0000 - accuracy: 0.6693\n",
            "Epoch 7/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 67066796.0000 - accuracy: 0.6751\n",
            "Epoch 8/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 54926832.0000 - accuracy: 0.6713\n",
            "Epoch 9/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 53039332.0000 - accuracy: 0.6737\n",
            "Epoch 10/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 51125172.0000 - accuracy: 0.6736\n",
            "Epoch 11/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 45697708.0000 - accuracy: 0.6777\n",
            "Epoch 12/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 43808512.0000 - accuracy: 0.6701\n",
            "Epoch 13/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 44039044.0000 - accuracy: 0.6726\n",
            "Epoch 14/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 44208296.0000 - accuracy: 0.6736\n",
            "Epoch 15/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 42307160.0000 - accuracy: 0.6715\n",
            "Epoch 16/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 43049040.0000 - accuracy: 0.6684\n",
            "Epoch 17/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 38409772.0000 - accuracy: 0.6686\n",
            "Epoch 18/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 33287824.0000 - accuracy: 0.6754\n",
            "Epoch 19/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 33971976.0000 - accuracy: 0.6758\n",
            "Epoch 20/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 32397198.0000 - accuracy: 0.6751\n",
            "Epoch 21/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 35334024.0000 - accuracy: 0.6681\n",
            "Epoch 22/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 27062498.0000 - accuracy: 0.6713\n",
            "Epoch 23/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 29439146.0000 - accuracy: 0.6726\n",
            "Epoch 24/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 32387476.0000 - accuracy: 0.6725\n",
            "Epoch 25/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 29351922.0000 - accuracy: 0.6696\n",
            "Epoch 26/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 24576132.0000 - accuracy: 0.6684\n",
            "Epoch 27/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 25336794.0000 - accuracy: 0.6763\n",
            "Epoch 28/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 25257048.0000 - accuracy: 0.6713\n",
            "Epoch 29/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 25171494.0000 - accuracy: 0.6753\n",
            "Epoch 30/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 19064962.0000 - accuracy: 0.6682\n",
            "Epoch 31/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 14373750.0000 - accuracy: 0.6768\n",
            "Epoch 32/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 11565543.0000 - accuracy: 0.6734\n",
            "Epoch 33/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 12335339.0000 - accuracy: 0.6725\n",
            "Epoch 34/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 10841919.0000 - accuracy: 0.6792\n",
            "Epoch 35/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 9358704.0000 - accuracy: 0.6709\n",
            "Epoch 36/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 10321354.0000 - accuracy: 0.6664\n",
            "Epoch 37/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 10631732.0000 - accuracy: 0.6822\n",
            "Epoch 38/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 9807449.0000 - accuracy: 0.6715\n",
            "Epoch 39/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 8546709.0000 - accuracy: 0.6743\n",
            "Epoch 40/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 9800415.0000 - accuracy: 0.6754\n",
            "Epoch 41/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 7899857.5000 - accuracy: 0.6674\n",
            "Epoch 42/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 9833415.0000 - accuracy: 0.6758\n",
            "Epoch 43/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 7886181.5000 - accuracy: 0.6764\n",
            "Epoch 44/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 7172192.0000 - accuracy: 0.6749\n",
            "Epoch 45/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 1588262.6250 - accuracy: 0.5265\n",
            "Epoch 46/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 2.0089 - accuracy: 0.8144\n",
            "Epoch 47/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 1.7124 - accuracy: 0.8144\n",
            "Epoch 48/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 1.4841 - accuracy: 0.8144\n",
            "Epoch 49/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 1.3084 - accuracy: 0.8144\n",
            "Epoch 50/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 1.1747 - accuracy: 0.8144\n",
            "Epoch 51/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 1.0747 - accuracy: 0.8144\n",
            "Epoch 52/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 1.0007 - accuracy: 0.8144\n",
            "Epoch 53/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.9465 - accuracy: 0.8144\n",
            "Epoch 54/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.9070 - accuracy: 0.8144\n",
            "Epoch 55/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8782 - accuracy: 0.8144\n",
            "Epoch 56/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8573 - accuracy: 0.8144\n",
            "Epoch 57/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8419 - accuracy: 0.8144\n",
            "Epoch 58/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8306 - accuracy: 0.8144\n",
            "Epoch 59/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8221 - accuracy: 0.8144\n",
            "Epoch 60/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8156 - accuracy: 0.8144\n",
            "Epoch 61/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8106 - accuracy: 0.8144\n",
            "Epoch 62/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8067 - accuracy: 0.8144\n",
            "Epoch 63/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8036 - accuracy: 0.8144\n",
            "Epoch 64/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.8011 - accuracy: 0.8144\n",
            "Epoch 65/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7990 - accuracy: 0.8144\n",
            "Epoch 66/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7973 - accuracy: 0.8144\n",
            "Epoch 67/150\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 0.7959 - accuracy: 0.8144\n",
            "Epoch 68/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7947 - accuracy: 0.8144\n",
            "Epoch 69/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7937 - accuracy: 0.8144\n",
            "Epoch 70/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7929 - accuracy: 0.8144\n",
            "Epoch 71/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7923 - accuracy: 0.8144\n",
            "Epoch 72/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7917 - accuracy: 0.8144\n",
            "Epoch 73/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7913 - accuracy: 0.8144\n",
            "Epoch 74/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7909 - accuracy: 0.8144\n",
            "Epoch 75/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7905 - accuracy: 0.8144\n",
            "Epoch 76/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7903 - accuracy: 0.8144\n",
            "Epoch 77/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7901 - accuracy: 0.8144\n",
            "Epoch 78/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7899 - accuracy: 0.8144\n",
            "Epoch 79/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7897 - accuracy: 0.8144\n",
            "Epoch 80/150\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 0.7896 - accuracy: 0.8144\n",
            "Epoch 81/150\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 0.7895 - accuracy: 0.8144\n",
            "Epoch 82/150\n",
            "222/222 [==============================] - 2s 8ms/step - loss: 0.7894 - accuracy: 0.8144\n",
            "Epoch 83/150\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 0.7893 - accuracy: 0.8144\n",
            "Epoch 84/150\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 0.7892 - accuracy: 0.8144\n",
            "Epoch 85/150\n",
            "222/222 [==============================] - 2s 8ms/step - loss: 0.7892 - accuracy: 0.8144\n",
            "Epoch 86/150\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 0.7891 - accuracy: 0.8144\n",
            "Epoch 87/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7891 - accuracy: 0.8144\n",
            "Epoch 88/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7890 - accuracy: 0.8144\n",
            "Epoch 89/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7890 - accuracy: 0.8144\n",
            "Epoch 90/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7890 - accuracy: 0.8144\n",
            "Epoch 91/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7890 - accuracy: 0.8144\n",
            "Epoch 92/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.8144\n",
            "Epoch 93/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.8144\n",
            "Epoch 94/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.8144\n",
            "Epoch 95/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.8144\n",
            "Epoch 96/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.8144\n",
            "Epoch 97/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.8144\n",
            "Epoch 98/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.8144\n",
            "Epoch 99/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.8144\n",
            "Epoch 100/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 101/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 102/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 103/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 104/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 105/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 106/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 107/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 108/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 109/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 110/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 111/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 112/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 113/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 114/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 115/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 116/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 117/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 118/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 119/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 120/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 121/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 122/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 123/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 124/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 125/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 126/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 127/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 128/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 129/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 130/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 131/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 132/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 133/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 134/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 135/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 136/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 137/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 138/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 139/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 140/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 141/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 142/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 143/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 144/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 145/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 146/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 147/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 148/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 149/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "Epoch 150/150\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.8144\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "95/95 [==============================] - 0s 5ms/step - loss: 0.8351 - accuracy: 0.7995\n",
            "[0.8351374268531799, 0.7995391488075256]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAbuJoLIs8BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}